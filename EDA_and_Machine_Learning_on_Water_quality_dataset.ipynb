{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMY4O0MUhkchUfAyHepIOIB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ash100/Trainings/blob/main/EDA_and_Machine_Learning_on_Water_quality_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "My name is Dr. Ashfaq Ahmad, and I work in the field of Bioinformatics, Data science and Structural Biology. This training is prepared on a water quality dataset to teach you how well you can play with data.\n",
        "\n",
        "You are welcome to follow me on youtube [**Bioinformatics Insights**](www.youtube.com/@Bioinformaticsinsights)"
      ],
      "metadata": {
        "id": "PXVDAy_n5AMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis (EDA) of Water Quality Dataset\n",
        "In this section, we will perform Exploratory Data Analysis (EDA) on the water quality dataset using Google Colab. We will use Python libraries such as pandas, matplotlib, and seaborn to visualize and understand the data."
      ],
      "metadata": {
        "id": "e08WimUxuqPE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**First, we need to import the necessary libraries for data manipulation and visualization.**"
      ],
      "metadata": {
        "id": "CWzqEbBvu1jQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XLbx3eGbuo0M",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Necessary Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next, we load the dataset into a pandas DataFrame. For this example, we will create the DataFrame directly from the provided data.**"
      ],
      "metadata": {
        "id": "KGJo40IJu_g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load your dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from google.colab import files\n",
        "\n",
        "# Step 2: Upload the CSV file\n",
        "print(\"Please upload your CSV file:\")\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "YVYkqiB5vCiy",
        "cellView": "form",
        "outputId": "79161fc9-a538-4731-ad9c-1e4c3c650cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your CSV file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3339bb22-4a29-4b12-8d8e-d5ba18819882\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3339bb22-4a29-4b12-8d8e-d5ba18819882\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving water_potability.csv to water_potability.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the data into a pandas DataFrame\n",
        "file_name = list(uploaded.keys())[0]  # Get the name of the uploaded file\n",
        "df = pd.read_csv('/content/water_potability.csv')"
      ],
      "metadata": {
        "id": "bsrsTZMCvm1a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Display basic information about the dataset\n",
        "print(\"Basic Information about the Dataset:\")\n",
        "print(df.info())\n",
        "print(\"\\nFirst few rows of the dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "BjPOkA2SvwTJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Data Processing - Handle missing values by filling them with the mean of the column\n",
        "df.fillna(df.mean(), inplace=True)"
      ],
      "metadata": {
        "id": "QiDZ5ECDv3Ii"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save descriptive statistics to a CSV file in /content\n",
        "descriptive_stats = df.describe()\n",
        "descriptive_stats.to_csv('/content/descriptive_stats.csv', index=True)\n",
        "\n",
        "print(\"Descriptive statistics saved to /content/descriptive_stats.csv\")"
      ],
      "metadata": {
        "id": "A8UrEboCwH3M",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will create various visualizations to understand the distribution and relationships within the data.**"
      ],
      "metadata": {
        "id": "aBs2gQezwxpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize - Histograms for each feature\n",
        "df.hist(bins=15, figsize=(15, 10), layout=(4, 3))\n",
        "plt.suptitle('Histograms of Water Quality Features', fontsize=16)\n",
        "\n",
        "# Save the figure as PNG with 600 DPI\n",
        "plt.savefig('/content/water_quality_feature_histograms.png', dpi=600, bbox_inches='tight')\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "exPEG1dXw0OA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize - Box Plot for each feature\n",
        "plt.figure(figsize=(15, 10))\n",
        "df.boxplot()\n",
        "plt.title('Boxplots of Water Quality Features')\n",
        "\n",
        "# Save the figure as PNG with 600 DPI\n",
        "plt.savefig('/content/boxplots_water_quality.png', dpi=600, bbox_inches='tight')\n",
        "\n",
        "# Show the plots\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0csAp3kdxVrr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize - the correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Correlation Matrix of Water Quality Features')\n",
        "\n",
        "# Save the heatmap as a high-resolution PNG\n",
        "plt.savefig('/content/correlation_heatmap.png', dpi=600, bbox_inches='tight')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tRN0StBIxwO7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize - thePairplot with hue based on 'Potability'\n",
        "pairplot = sns.pairplot(df, hue='Potability')\n",
        "\n",
        "# Save the pairplot as a high-resolution PNG\n",
        "plt.savefig('/content/water_quality_pairplot.png', dpi=600, bbox_inches='tight')\n",
        "\n",
        "# Show the pairplot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JvktIgoDyL1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Compare two different features - Hardness vs. Conductivity\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x='Hardness', y='Conductivity', hue='Potability', data=df)\n",
        "plt.title('Scatter Plot of Hardness vs. Tirbidity')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tfrLf2-XzEsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpretation of the above\n",
        "**Histograms**\n",
        "\n",
        "Histograms provide a visual representation of the distribution of each feature. They help identify the range, central tendency, and spread of the data. For example, the histogram of Hardness shows a relatively normal distribution, while Solids has a more skewed distribution.\n",
        "\n",
        "**Boxplots**\n",
        "\n",
        "Boxplots are useful for identifying outliers and understanding the spread of the data. They show the median, quartiles, and potential outliers. For instance, the boxplot of Chloramines indicates that there are no significant outliers in this feature.\n",
        "\n",
        "**Correlation Matrix**\n",
        "\n",
        "The correlation matrix helps identify relationships between features. A high positive correlation (close to 1) indicates a strong positive relationship, while a high negative correlation (close to -1) indicates a strong negative relationship. For example, Hardness and Conductivity have a moderate positive correlation.\n",
        "\n",
        "**Pairplot**\n",
        "\n",
        "Pairplots provide a comprehensive view of pairwise relationships between features. They help identify patterns and relationships that might not be apparent from individual plots. The pairplot with hue based on Potability helps visualize how different features relate to water potability.\n",
        "\n",
        "**Scatter Plots**\n",
        "\n",
        "Scatter plots are useful for visualizing the relationship between two features. They help identify trends and patterns. For example, the scatter plot of Hardness vs. Conductivity shows a positive trend, indicating that higher hardness is associated with higher conductivity."
      ],
      "metadata": {
        "id": "50Fe61xPzNIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning on Water Quality Data"
      ],
      "metadata": {
        "id": "D3EQX-C20_u6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "1. **Handle Missing Values**: Fill missing values with the mean of the respective column.\n",
        "2. **Split Data**: Split the data into features (X) and target (y).\n",
        "3. **Standardize Features**: Standardize the features using `StandardScaler`."
      ],
      "metadata": {
        "id": "8N9pnI2y1JfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Necessary Import\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "2Tqn6B4Z1elr",
        "cellView": "form"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Handle missing values\n",
        "df.fillna(df.mean(), inplace=True)\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop(columns=['Potability'])\n",
        "y = df['Potability']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "lJYjOhq11Fpp",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Multiple Models\n",
        "\n",
        "1. **Logistic Regression**\n",
        "2. **Random Forest**\n",
        "3. **Gradient Boosting**\n",
        "4. **Support Vector Machine (SVM)**\n",
        "5. **K-Nearest Neighbors (KNN)**\n",
        "6. **Decision Tree**\n",
        "\n",
        "Evaluate each model using accuracy, precision, recall, and F1-score."
      ],
      "metadata": {
        "id": "q2_xgvqF1oFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Define and Machine Learning Models and Choose the Best\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Split data into training and testing sets\n",
        "test_size = 0.1  # Adjust as needed\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    results[name] = accuracy\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"{name} Classification Report:\\n{report}\\n\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3eEiLrc2Oy2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Key Visualizations:\n",
        "**Confusion Matrix:**\n",
        "Shows TP, TN, FP, FN.\n",
        "\n",
        "**ROC Curve:**\n",
        "Evaluates the trade-off between TPR and FPR.\n",
        "\n",
        "**Precision-Recall Curve:**\n",
        "Highlights performance for imbalanced data."
      ],
      "metadata": {
        "id": "pOADIvIh4wOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Analysis\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "\n",
        "# Find the best model based on accuracy\n",
        "best_model_name = max(results, key=lambda k: results[k])\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "# Generate predictions and classification report\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(f\"\\n{best_model_name} Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 1. Confusion Matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "plt.show()\n",
        "\n",
        "# 2. ROC Curve\n",
        "if hasattr(best_model, \"predict_proba\"):\n",
        "    y_scores = best_model.predict_proba(X_test)[:, 1]\n",
        "else:\n",
        "    y_scores = best_model.decision_function(X_test)\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(f'ROC Curve - {best_model_name}')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 3. Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
        "avg_precision = average_precision_score(y_test, y_scores)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {avg_precision:.2f})')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title(f'Precision-Recall Curve - {best_model_name}')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# 4. Feature Importance (for tree-based models)\n",
        "if isinstance(best_model, (RandomForestClassifier, GradientBoostingClassifier)):\n",
        "    plt.figure(figsize=(10,8))\n",
        "    feature_importance = best_model.feature_importances_\n",
        "    sorted_idx = np.argsort(feature_importance)[::-1]\n",
        "    plt.barh(X_train.columns[sorted_idx], feature_importance[sorted_idx], align='center')\n",
        "    plt.xlabel('Feature Importance')\n",
        "    plt.ylabel('Features')\n",
        "    plt.title(f'Feature Importance - {best_model_name}')\n",
        "    plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "YHwRaNes4ICX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Select the Best Model\n",
        "\n",
        "Compare the accuracy of each model and select the best-performing model."
      ],
      "metadata": {
        "id": "G4b6tHHW2j06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select the best model\n",
        "best_model_name = max(results, key=results.get)\n",
        "best_model = models[best_model_name]\n",
        "print(f\"Best Model: {best_model_name} with Accuracy: {results[best_model_name]:.4f}\")"
      ],
      "metadata": {
        "id": "5NeK7RqH2oCC",
        "cellView": "form",
        "outputId": "2dab0c6c-9b7d-4dc8-e672-5780a297ac8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: SVM with Accuracy: 0.6951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate and visualize the feature importance based on the best model.**"
      ],
      "metadata": {
        "id": "_CN1RJUH29HS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feature Importance\n",
        "if not isinstance(X, pd.DataFrame):\n",
        "    X = pd.DataFrame(X, columns=df.columns[:-1])  # Exclude the target column 'Potability'\n",
        "\n",
        "# Check the type of the best model\n",
        "if isinstance(best_model, (RandomForestClassifier, GradientBoostingClassifier)):\n",
        "    # For RandomForestClassifier and GradientBoostingClassifier\n",
        "    feature_importances = best_model.feature_importances_\n",
        "    feature_names = X.columns\n",
        "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "elif isinstance(best_model, LogisticRegression):\n",
        "    # For LogisticRegression\n",
        "    feature_importances = best_model.coef_[0]\n",
        "    feature_names = X.columns\n",
        "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "elif isinstance(best_model, (SVC, KNeighborsClassifier, DecisionTreeClassifier)):\n",
        "    # For other models, use permutation importance\n",
        "    from sklearn.inspection import permutation_importance\n",
        "    importances = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42)\n",
        "    feature_importances = importances.importances_mean\n",
        "    feature_names = X.columns\n",
        "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "else:\n",
        "    print(\"Feature importance calculation is not supported for this model type.\")\n",
        "    feature_importance_df = None\n",
        "\n",
        "# Plot feature importances if available\n",
        "if feature_importance_df is not None:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
        "    plt.title('Feature Importances')\n",
        "\n",
        "    # Save the plot with high resolution\n",
        "    plt.savefig('feature_importances.png', dpi=600)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "F95XVxEb2-Aj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the Best Model For Prediction"
      ],
      "metadata": {
        "id": "BfuTjo_p4zjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the unknown data\n",
        "print(\"Please upload your unknown data CSV file:\")\n",
        "unknown_data = files.upload()\n",
        "\n",
        "# Load the unknown data into a pandas DataFrame\n",
        "unknown_file_name = list(unknown_data.keys())[0]  # Get the name of the uploaded file\n",
        "unknown_df = pd.read_csv(unknown_file_name)\n",
        "\n",
        "# Display the first few rows of the unknown data\n",
        "print(\"First few rows of the unknown data:\")\n",
        "print(unknown_df.head())"
      ],
      "metadata": {
        "id": "uNZfhNG_43oA",
        "cellView": "form",
        "outputId": "6733eed2-e8b1-43b4-a26f-ccb2d38b1875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your unknown data CSV file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7f590771-9bef-49a7-9240-5f3ede44b820\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7f590771-9bef-49a7-9240-5f3ede44b820\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving unknown_data_predictions.csv to unknown_data_predictions.csv\n",
            "First few rows of the unknown data:\n",
            "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
            "0  7.666856  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
            "1  3.716080  129.422921  18630.057858     6.635246  343.198307    592.885359   \n",
            "2  8.099124  224.236259  19909.541732     9.275884  343.198307    418.606213   \n",
            "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
            "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
            "\n",
            "   Organic_carbon  Trihalomethanes  Turbidity  \n",
            "0       10.379783        86.990970   2.963135  \n",
            "1       15.180013        56.329076   4.500656  \n",
            "2       16.868637        66.420093   3.055934  \n",
            "3       18.436524       100.341674   4.628771  \n",
            "4       11.558279        31.997993   4.075075  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocess the unknown data\n",
        "# Handle missing values\n",
        "unknown_df.fillna(unknown_df.mean(), inplace=True)\n",
        "\n",
        "# Ensure the unknown data has the same columns as the training data\n",
        "if not set(unknown_df.columns).issubset(set(X.columns)):\n",
        "    print(\"Unknown data columns do not match the training data columns.\")\n",
        "    print(\"Training data columns:\", X.columns)\n",
        "    print(\"Unknown data columns:\", unknown_df.columns)\n",
        "    raise ValueError(\"Columns mismatch between training and unknown data.\")\n",
        "\n",
        "# Standardize the unknown data using the same scaler\n",
        "unknown_df_scaled = scaler.transform(unknown_df)"
      ],
      "metadata": {
        "id": "HeJOs0Ys5DrK",
        "cellView": "form"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Make predictions on the unknown data\n",
        "predictions = best_model.predict(unknown_df_scaled)\n",
        "\n",
        "# Add predictions to the unknown data DataFrame\n",
        "unknown_df['Predicted_Potability'] = predictions\n",
        "\n",
        "# Display the first few rows of the unknown data with predictions\n",
        "print(\"First few rows of the unknown data with predictions:\")\n",
        "print(unknown_df.head())"
      ],
      "metadata": {
        "id": "IS9ZOQMs5Gsp",
        "cellView": "form",
        "outputId": "9d033406-3e55-4e04-981a-4b4a1c3f5338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the unknown data with predictions:\n",
            "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
            "0  7.666856  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
            "1  3.716080  129.422921  18630.057858     6.635246  343.198307    592.885359   \n",
            "2  8.099124  224.236259  19909.541732     9.275884  343.198307    418.606213   \n",
            "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
            "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
            "\n",
            "   Organic_carbon  Trihalomethanes  Turbidity  Predicted_Potability  \n",
            "0       10.379783        86.990970   2.963135                     0  \n",
            "1       15.180013        56.329076   4.500656                     0  \n",
            "2       16.868637        66.420093   3.055934                     0  \n",
            "3       18.436524       100.341674   4.628771                     0  \n",
            "4       11.558279        31.997993   4.075075                     0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the predictions to a CSV file\n",
        "output_file_name = 'unknown_data_predictions_1.csv'\n",
        "unknown_df.to_csv(output_file_name, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file_name}\")"
      ],
      "metadata": {
        "id": "Z9NMAy6d5OYa",
        "outputId": "ba93e442-6a35-411c-cc23-582d2b503a35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to unknown_data_predictions_1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Today, you learned something new. Isn't great.\n",
        "\n",
        "[**Data Analysis on Weather Dataset**](https://youtu.be/qm7n8Fc8T74)"
      ],
      "metadata": {
        "id": "O4mOS7IC5awu"
      }
    }
  ]
}